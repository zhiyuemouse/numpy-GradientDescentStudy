{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e69733d",
   "metadata": {},
   "source": [
    "# 手撕常见算法面试题目\n",
    "##### zhiyue_mouse最爱版\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3470b",
   "metadata": {},
   "source": [
    "### 线性回归\n",
    "\n",
    "#### 原理\n",
    "线性回归假设目标变量y与特征x之间存在线性关系：\n",
    "\n",
    "\n",
    "$y = Xw + b$，其中$X$是特征矩阵，$w$是权重向量，$b$是偏置。\n",
    "\n",
    "\n",
    "损失函数为MSE：\n",
    "\n",
    "\n",
    "$J(w,b) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_w(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "梯度下降更新：\n",
    "$w_j = w_j - \\alpha\\frac{\\partial J}{\\partial w_j} = w_j - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h_w(x^{(i)}) - y^{(i)})x_j^{(i)}$\n",
    "\n",
    "$b = b - \\alpha\\frac{\\partial J}{\\partial b} = b - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h_w(x^{(i)}) - y^{(i)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68f78b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Weights: [0.15 0.15], Bias: 0.05\n",
      "Iteration 101: Weights: [0.9542206 0.9542206], Bias: 0.2717865473927469\n",
      "Iteration 201: Weights: [0.96090859 0.96090859], Bias: 0.23208088730299303\n",
      "Iteration 301: Weights: [0.96661951 0.96661951], Bias: 0.1981758738605035\n",
      "Iteration 401: Weights: [0.97149611 0.97149611], Bias: 0.16922409008674807\n",
      "Iteration 501: Weights: [0.97566028 0.97566028], Bias: 0.14450191190197753\n",
      "Iteration 601: Weights: [0.97921611 0.97921611], Bias: 0.12339143045545621\n",
      "Iteration 701: Weights: [0.98225245 0.98225245], Bias: 0.10536500804343571\n",
      "Iteration 801: Weights: [0.98484522 0.98484522], Bias: 0.08997209027413752\n",
      "Iteration 901: Weights: [0.9870592 0.9870592], Bias: 0.07682794486154712\n",
      "Predictions: [2.04357228 4.02143683 5.99930138 7.97716592]\n",
      "Mean Squared Error: 0.0007199911707355395\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            if _ % 100 == 0:\n",
    "                print(f\"Iteration {_+1}: Weights: {self.weights}, Bias: {self.bias}\")\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "    \n",
    "    def mean_squared_erorr(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "X = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\n",
    "y = np.array([2, 4, 6, 8])\n",
    "regressor = LinearRegression(learning_rate=0.01, n_iters=1000)\n",
    "regressor.fit(X, y)\n",
    "predictions = regressor.predict(X)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Mean Squared Error:\", regressor.mean_squared_erorr(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e63392",
   "metadata": {},
   "source": [
    "#### 逻辑回归\n",
    "原理\n",
    "\n",
    "Sigmoid函数：\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "假设函数（交叉熵）：\n",
    "\n",
    "$J(w,b) = -\\frac{1}{m} \\sum_{i=1}^{m}[y^{(i)}\\log(h_w(x^{(i)})) + (1-y^{(i)}\\log(1-h_w(x^{(i)})))]$\n",
    "\n",
    "梯度更新：\n",
    "\n",
    "$w_j = w_j - \\alpha\\frac{\\partial J}{\\partial w_j} = w_j - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}{h_w(x^{(i)})x_j^{(i)}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f543d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Iteration 0, Loss: 0.6931\n",
      "Iteration 100, Loss: 0.1720\n",
      "Iteration 200, Loss: 0.1215\n",
      "Iteration 300, Loss: 0.1006\n",
      "Iteration 400, Loss: 0.0888\n",
      "Iteration 500, Loss: 0.0810\n",
      "Iteration 600, Loss: 0.0753\n",
      "Iteration 700, Loss: 0.0710\n",
      "Iteration 800, Loss: 0.0676\n",
      "Iteration 900, Loss: 0.0649\n",
      "Test Accuracy: 0.9500\n",
      "Sample predictions (probability, prediction, true):\n",
      "  0.0021, False, 0\n",
      "  0.9802, True, 1\n",
      "  0.9969, True, 1\n",
      "  0.0151, False, 0\n",
      "  0.9983, True, 1\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # 梯度下降\n",
    "        for i in range(self.n_iters):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self._sigmoid(linear_model)\n",
    "            \n",
    "            # 计算梯度\n",
    "            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            # 更新参数\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                # 计算损失\n",
    "                loss = -np.mean(y * np.log(y_pred) + (1-y) * np.log(1-y_pred))\n",
    "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        return self._sigmoid(linear_model)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return self.predict_proba(X) >= threshold\n",
    "\n",
    "# 测试逻辑回归\n",
    "print(\"\\n=== Logistic Regression ===\")\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, \n",
    "                          n_informative=2, random_state=42)\n",
    "\n",
    "# 分割数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练\n",
    "log_reg = LogisticRegression(learning_rate=0.1, n_iters=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = log_reg.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 输出概率\n",
    "y_proba = log_reg.predict_proba(X_test)\n",
    "print(\"Sample predictions (probability, prediction, true):\")\n",
    "for i in range(5):\n",
    "    print(f\"  {y_proba[i]:.4f}, {y_pred[i]}, {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97751da",
   "metadata": {},
   "source": [
    "#### Multi-head Self-Attention\n",
    "原理公式\n",
    "查询、键、值投影：\n",
    "\n",
    "$Q = XW^Q$, $K = XW^K$, $V = XW^V$\n",
    "\n",
    "缩放点积注意力：\n",
    "\n",
    "$\\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
    "\n",
    "多头注意力：\n",
    "\n",
    "$\\text{MultiHead}(Q,K,V) = \\text{Concat}(head_1,...,head_h)W^O$\n",
    "\n",
    "其中 \n",
    "\n",
    "$head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78a0f857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fixed Multi-head Self-Attention ===\n",
      "Input shape: (2, 4, 8)\n",
      "Output shape: (2, 4, 8)\n",
      "Attention weights shape: (2, 2, 4, 4)\n",
      "Attention weights for first head, first batch:\n",
      "[[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "\n",
      "Input range: [-2.025, 3.853]\n",
      "Output range: [-0.001, 0.001]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class MultiHeadSelfAttention:\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        # 权重矩阵 - 修正维度\n",
    "        self.W_q = np.random.randn(d_model, d_model) * 0.01\n",
    "        self.W_k = np.random.randn(d_model, d_model) * 0.01\n",
    "        self.W_v = np.random.randn(d_model, d_model) * 0.01\n",
    "        self.W_o = np.random.randn(d_model, d_model) * 0.01\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "    \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Q, K, V 形状: (batch_size, num_heads, seq_len, d_k)\n",
    "        \n",
    "        # 修正矩阵乘法维度\n",
    "        # K 需要转置最后两个维度: (batch_size, num_heads, d_k, seq_len)\n",
    "        scores = np.matmul(Q, K.swapaxes(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores + mask * -1e9\n",
    "            \n",
    "        attention_weights = self.softmax(scores)\n",
    "        output = np.matmul(attention_weights, V)  # (batch_size, num_heads, seq_len, d_k)\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        \n",
    "        # 线性投影\n",
    "        Q = np.dot(x, self.W_q)  # (batch_size, seq_len, d_model)\n",
    "        K = np.dot(x, self.W_k)\n",
    "        V = np.dot(x, self.W_v)\n",
    "        \n",
    "        # 重塑为多头 - 修正维度变换\n",
    "        Q = Q.reshape(batch_size, seq_len, self.num_heads, self.d_k).transpose(0, 2, 1, 3)\n",
    "        K = K.reshape(batch_size, seq_len, self.num_heads, self.d_k).transpose(0, 2, 1, 3)\n",
    "        V = V.reshape(batch_size, seq_len, self.num_heads, self.d_k).transpose(0, 2, 1, 3)\n",
    "        # 现在形状: (batch_size, num_heads, seq_len, d_k)\n",
    "        \n",
    "        # 计算注意力\n",
    "        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # 合并多头 - 修正维度变换\n",
    "        attention_output = attention_output.transpose(0, 2, 1, 3)  # (batch_size, seq_len, num_heads, d_k)\n",
    "        attention_output = attention_output.reshape(batch_size, seq_len, d_model)\n",
    "        \n",
    "        # 输出投影\n",
    "        output = np.dot(attention_output, self.W_o)\n",
    "        \n",
    "        return output, attention_weights\n",
    "\n",
    "# 测试修复后的Multi-head Self-Attention\n",
    "print(\"\\n=== Fixed Multi-head Self-Attention ===\")\n",
    "# 创建示例数据\n",
    "batch_size, seq_len, d_model = 2, 4, 8\n",
    "num_heads = 2\n",
    "\n",
    "x = np.random.randn(batch_size, seq_len, d_model)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# 初始化注意力层\n",
    "attention = MultiHeadSelfAttention(d_model, num_heads)\n",
    "output, attn_weights = attention.forward(x)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Attention weights shape: {attn_weights.shape}\")\n",
    "\n",
    "# 显示注意力权重\n",
    "print(\"Attention weights for first head, first batch:\")\n",
    "print(attn_weights[0, 0].round(3))\n",
    "\n",
    "# 验证输出\n",
    "print(f\"\\nInput range: [{x.min():.3f}, {x.max():.3f}]\")\n",
    "print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc7253",
   "metadata": {},
   "source": [
    "#### K-means 聚类\n",
    "原理公式\n",
    "目标函数：\n",
    "\n",
    "$J = \\sum_{i=1}^{k}\\sum_{x\\in C_i}||x - \\mu_i||^2$\n",
    "\n",
    "质心更新：\n",
    "\n",
    "$\\mu_i = \\frac{1}{|C_i|}\\sum_{x\\in C_i}x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae937de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== K-means Clustering ===\n",
      "Iteration 0, Inertia: 8998.7533\n",
      "Converged at iteration 2\n",
      "Centroids:\n",
      "  Cluster 0: [-6.88387179 -6.98398415]\n",
      "  Cluster 1: [4.74710337 2.01059427]\n",
      "  Cluster 2: [-2.63323268  9.04356978]\n",
      "Adjusted Rand Index: 1.0000\n",
      "Cluster sizes: {np.int64(0): np.int64(100), np.int64(1): np.int64(100), np.int64(2): np.int64(100)}\n"
     ]
    }
   ],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k=3, max_iters=100):\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def _initialize_centroids(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        random_indices = np.random.choice(n_samples, self.k, replace=False)\n",
    "        return X[random_indices]\n",
    "    \n",
    "    def _assign_clusters(self, X):\n",
    "        distances = np.zeros((X.shape[0], self.k))\n",
    "        for i in range(self.k):\n",
    "            distances[:, i] = np.linalg.norm(X - self.centroids[i], axis=1)\n",
    "        return np.argmin(distances, axis=1)\n",
    "    \n",
    "    def _update_centroids(self, X, labels):\n",
    "        new_centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            if np.sum(labels == i) > 0:\n",
    "                new_centroids[i] = X[labels == i].mean(axis=0)\n",
    "            else:\n",
    "                new_centroids[i] = self.centroids[i]  # 保持原质心\n",
    "        return new_centroids\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.centroids = self._initialize_centroids(X)\n",
    "        \n",
    "        for i in range(self.max_iters):\n",
    "            # 分配簇\n",
    "            labels = self._assign_clusters(X)\n",
    "            \n",
    "            # 更新质心\n",
    "            new_centroids = self._update_centroids(X, labels)\n",
    "            \n",
    "            # 检查收敛\n",
    "            if np.allclose(self.centroids, new_centroids):\n",
    "                print(f\"Converged at iteration {i}\")\n",
    "                break\n",
    "                \n",
    "            self.centroids = new_centroids\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                inertia = self._compute_inertia(X, labels)\n",
    "                print(f\"Iteration {i}, Inertia: {inertia:.4f}\")\n",
    "        \n",
    "        self.labels = self._assign_clusters(X)\n",
    "        return self\n",
    "    \n",
    "    def _compute_inertia(self, X, labels):\n",
    "        inertia = 0\n",
    "        for i in range(self.k):\n",
    "            cluster_points = X[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                inertia += np.sum((cluster_points - self.centroids[i])**2)\n",
    "        return inertia\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._assign_clusters(X)\n",
    "\n",
    "# 测试K-means\n",
    "print(\"\\n=== K-means Clustering ===\")\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# 生成测试数据\n",
    "X, y_true = make_blobs(n_samples=300, centers=3, n_features=2, \n",
    "                       random_state=42, cluster_std=1.0)\n",
    "\n",
    "# 训练K-means\n",
    "kmeans = KMeans(k=3, max_iters=100)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 预测\n",
    "y_pred = kmeans.labels\n",
    "\n",
    "print(\"Centroids:\")\n",
    "for i, centroid in enumerate(kmeans.centroids):\n",
    "    print(f\"  Cluster {i}: {centroid}\")\n",
    "\n",
    "# 计算准确率（需要调整标签映射）\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari = adjusted_rand_score(y_true, y_pred)\n",
    "print(f\"Adjusted Rand Index: {ari:.4f}\")\n",
    "\n",
    "# 显示每个簇的大小\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print(\"Cluster sizes:\", dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fe8931",
   "metadata": {},
   "source": [
    "#### AUC 计算\n",
    "原理公式\n",
    "$AUC = \\frac{\\sum_{i=1}^{m}\\sum_{j=1}^{n}I(p_i > p_j)}{m \\times n}$\n",
    "\n",
    "其中 $I$ 是指示函数，$m$ 是正样本数，$n$ 是负样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c06c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AUC Calculation ===\n",
      "Manual AUC: 0.5122\n",
      "Sklearn AUC: 0.5122\n",
      "ROC curve points: 101\n",
      "First 5 ROC points (FPR, TPR):\n",
      "  (0.000, 0.000)\n",
      "  (0.023, 0.000)\n",
      "  (0.023, 0.018)\n",
      "  (0.045, 0.018)\n",
      "  (0.045, 0.036)\n"
     ]
    }
   ],
   "source": [
    "def calculate_auc(y_true, y_scores):\n",
    "    \"\"\"手撕AUC计算\"\"\"\n",
    "    # 将正负样本分开\n",
    "    pos_scores = y_scores[y_true == 1]\n",
    "    neg_scores = y_scores[y_true == 0]\n",
    "    \n",
    "    # 计算比较对\n",
    "    count = 0\n",
    "    for pos_score in pos_scores:\n",
    "        for neg_score in neg_scores:\n",
    "            if pos_score > neg_score:\n",
    "                count += 1\n",
    "            elif pos_score == neg_score:\n",
    "                count += 0.5\n",
    "    \n",
    "    auc = count / (len(pos_scores) * len(neg_scores))\n",
    "    return auc\n",
    "\n",
    "def roc_curve(y_true, y_scores):\n",
    "    \"\"\"计算ROC曲线点\"\"\"\n",
    "    # 按分数排序\n",
    "    sorted_indices = np.argsort(y_scores)[::-1]\n",
    "    y_true_sorted = y_true[sorted_indices]\n",
    "    y_scores_sorted = y_scores[sorted_indices]\n",
    "    \n",
    "    # 计算TPR和FPR\n",
    "    tpr, fpr = [0], [0]\n",
    "    tp, fp = 0, 0\n",
    "    total_p = np.sum(y_true == 1)\n",
    "    total_n = np.sum(y_true == 0)\n",
    "    \n",
    "    for i in range(len(y_true_sorted)):\n",
    "        if y_true_sorted[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        \n",
    "        tpr.append(tp / total_p)\n",
    "        fpr.append(fp / total_n)\n",
    "    \n",
    "    return fpr, tpr\n",
    "\n",
    "# 测试AUC计算\n",
    "print(\"\\n=== AUC Calculation ===\")\n",
    "# 生成示例数据\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "y_true = np.random.randint(0, 2, n_samples)\n",
    "y_scores = np.random.rand(n_samples)\n",
    "\n",
    "# 计算AUC\n",
    "auc_manual = calculate_auc(y_true, y_scores)\n",
    "print(f\"Manual AUC: {auc_manual:.4f}\")\n",
    "\n",
    "# 使用sklearn验证\n",
    "from sklearn.metrics import roc_auc_score, roc_curve as sk_roc_curve\n",
    "auc_sklearn = roc_auc_score(y_true, y_scores)\n",
    "print(f\"Sklearn AUC: {auc_sklearn:.4f}\")\n",
    "\n",
    "# 计算ROC曲线\n",
    "fpr, tpr = roc_curve(y_true, y_scores)\n",
    "print(f\"ROC curve points: {len(fpr)}\")\n",
    "\n",
    "# 显示前几个点\n",
    "print(\"First 5 ROC points (FPR, TPR):\")\n",
    "for i in range(min(5, len(fpr))):\n",
    "    print(f\"  ({fpr[i]:.3f}, {tpr[i]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74903b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
